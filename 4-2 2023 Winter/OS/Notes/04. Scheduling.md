# Scheduling Overview
- The problem
	- You have more jobs than CPU
		- ![[Pasted image 20230119154948.png|200]]
		- Have $k$ jobs ready to run  
		- Have $n$ ≥ 1 CPUs
- Policy:
	- which jobs should we assign to which CPU(s) & for how long?
		- We’ll refer to schedulable entities as jobs – could be processes, threads, people, etc.
		- Only greedy algorithm
- Mechanism:
	- Context Switch
## When do we schedule the CPU?
- ![[Pasted image 20230119155429.png|300]]
	- Scheduler takes place pretty much every state switch
		- running to waiting
		- running to ready
		- new/waiting to ready
		- exits
	- Goal: Decide which job to do next to guarantee a good experience for user
		- fast, reliable
# Scheduling Criteria
- Throughput (higher is better)
	- \# of processes that complete per unit time
		- $\text{\#jobs}/\text{time}$
- Turnaround time (lower is better)
	- time for each process to complete
		- $T_{\text{completion}} - T_{\text{arrival}}$ (create to finish)
			- Not the same as execution time, as turnaround time include non-executing time!
			- Arrival time is when the job gets in the queue
- Response time (lower is better)
	- time from request to first response 
		- $T_{\text{firstrun}} - T_{\text{arrival}}$ (create to first ran)
- Above criteria are affected by secondary criteria
	- CPU utilization: fraction of / how much time CPU is doing productive work
		- We want to max it out
		- Concurrent running cores will make this criteria surpass 100%. (e.g. 4 cores all 100% = 400% CPU utilization)
## Scheduling Goals Differ
- Batch systems
	- e.g. servers
	- Strive for job throughput, turnaround time (supercomputers)
		- Don't care about the response time
- Interactive systems
	- e.g. PC
	- Strive for minimal response time
# Scheduling Algorithm
## FCFS (FIFO, Queue) Scheduling
- Run jobs in order that they arrive 
	- “First-come first-served” 
	- If tied arrival, choose lower PID first
	- ![[Pasted image 20230119161606.png|250]]
		- (Always start at zero in graph's timeline)
		- P2 & P3 tied in arrival, P2 prioritized because of its less execution time
		- Turnaround Time
			- P1 = 24 - 0 = 24
			- P2 = 27 - 0 = 27
			- P3 = 30 - 0 = 30
			- Avg = (24+27+30)/3
		- Throughput
			- 3 / 30 = 0.1 job/sec
		- Improvements?
			- Throughput: No
			- Turnaround Time: Schedule faster tasks first
## FCFS (FIFO, Queue) Scheduling 2
- Schedule faster tasks first
	- ![[Pasted image 20230119162529.png|200]]
		- Turnaround Time
			- ((3-0)+(6-0)+(30-0))/3
		- Throughput
			- Same 0.1 job/sec
## Shortest Job First (SJF)
- Choose the job with the smallest CPU burst
- This is the provably optimal average turnaround time if jobs arrive at the same time
## SJF II (Radom Arrival) 
- However, the system won't usually have jobs arriving the exact time.
- 2 Schemes
	- Non-preemptive
		- Once CPU given to the process it cannot be preempted until completes its CPU burst. (Can't interrupt running processes.)
	- Preemptive
		- If a new process arrives with CPU burst length less than remaining time of current executing process, preempt. 
		- Called Shortest Time-to-Completion First (STCF) (& aka Shortest-Remaining-Time-First or SRTF)
### From SJF to STCF
- SJF (Non-Preemptive)
	- ![[Pasted image 20230119163256.png|300]]
		- Arrival Time 
			- A = 0
			- B = 10
			- C = 10
		- Burst Time
			- A = 100
			- B = 10
			- C =10
		- Turnaround Time:
			- A = 100 - 0 = 100
			- B = 110 - 10 = 100
			- C = 120 - 10 = 110
			- Avg = ~103 (Worst)
- STCF (Preemptive)
	- ![[Pasted image 20230119165012.png|250]]
		- Arrival & Burst Time same
		- Turnaround Time:
			- A = 120 - 0 = 120
			- B = 20 - 10 = 10
			- C = 30 - 10 = 20
			- Avg = 50 (Better)
## Scheduling with I/O
- FIFO Scheduler
	- A: 
		- CPU = 50ms,
		- I/O = 40ms, 
		- 10ms intervals
			- Consider as 10ms subjobs (CPU, then I/O)
	- B: 
		- CPU = 50ms,
		- I/O = 0ms
- Without I/O Consideration
	- ![[Pasted image 20230119172457.png|300]] ![[Pasted image 20230119172510.png|210]]
		- BAD! CPU is wasted waiting for I/O
- With I/O Consideration
	- ![[Pasted image 20230119172547.png|300]]![[Pasted image 20230119172559.png|200]]
		- We switch to B to eliminate CPU wasting time
		- We switch back to A because we know it works in intervals of 10ms, that's the Burst Time
## SJF and STCF Limitations
- Impossible to know time of CPU burst
	- We can estimate fixed jobs, but jobs w/ interactivity makes it impossible
- Doesn't always minimize response time
	- Job that is very long gets thrown under the bus if more shorter ones keep arriving
- Can potentially lead to unfairness or starvation
## Round Robin
- Solution to fairness and starvation
	- Each job is given a time slice called a quantum
		- Can be short or long, depends on system requirements
		-  If we have a fixed quantum time $x$ with $n$ jobs, the response time is guaranteed at $(n-1)*x$
	- Preempt job after duration of quantum 
		- Because it doesn't care for a job's priority
	- When preempted, move to back of the FIFO queue (aka the line)
- Advantages:
	- Fair allocation of CPU across jobs
	- Low average response time when job length vary
- Disadvantage
	- Turnaround Time is worse
	- Lots of context switching, that's the overhead.
### Example
- ![[Pasted image 20230124154652.png|400]]
	- Response Time is much better by Round Robin
	- Turnaround Time is worse
### Time Quantum
- ![[Pasted image 20230124155838.png|300]]
- Too much context switching makes Round Robin redundant
- Typical Values are around 1-100ms
-----
# Multi-Level Feedback Queues (MLFQ)
- This is the real deal, unlike the previous basic stuff
- It can work without a priori knowledge of job length
- Objectives
	- Improve turnaround time: Run shorter jobs first
	- Minimize response time: Important for interactive jobs (UI)
- Multiple Job Queues
	- ![[Pasted image 20230124161358.png|150]]
		- Round Robin in each queue
	- Adjust job priority based on observed behavior
		- Interactive Jobs: High Priority
			- We can tell by frequent I/O, so let's keep priority high
				- since interactive jobs require fast response time (GUI/UI)
		- Batch Jobs
			- We can tell by it using long periods of CPU utilization, so keep the priority low
	- Rules:
		- If Priority(J1)>Priority(J2), J1 runs
		- If Priority(J1)=Priority(J2), RR
		- When a job enters the system, it is placed at the highest priority
		- If a job uses up an entire time slice while running, its priority is reduced
			- Probably a batch job
		- If a job gives up the CPU before the time slice is up, it stays at the same priority level
	- Approximates SJF, but smarter and robust
## Example 1: Long Running Job
- ![[Pasted image 20230124162755.png|200]]
	- Time Slice = 10ms
	- After each 10ms, the job got its priority reduced
## Example 2: Long and Short Jobs
- A 
	- arrival_time =0ms
	- run_time=200ms
- B
	- arrival_time =100ms, 
	- run_time =20ms
- Time Slice = 10ms
	- ![[Pasted image 20230124163155.png|300]]
		- B pre-emptively interrupts A with it's higher priority
## Issues
- Starvation
	- ![[Pasted image 20230124165932.png|300]]
		- The gap is between priority is bad
- Gaming the scheduler
	- Send fake I/O request, keep high priority
	- Job behavioral change
		- Batch switches back to interactive process
### Preventing Starvation
- Priority Boost: After some period S, allow the lowered job to boost back to highest priority
	- Give more chances to allow better priority consideration
#### Example
-   Boost every S = 50ms
	- ![[Pasted image 20230124170413.png|250]]
		- On the right, A is allowed to run when the interactive jobs arrive in a round robin fashion
### Preventing Gaming
- Improved time accounting: 
	- Track total job execution time in the queue (different from Time Slice)
	- Each job receives a fixed time allotment
	- When allotment is exhausted, job priority is lowered
#### Example
- ![[Pasted image 20230124171747.png|250]]
	- On the right. the interactive jobs still decreased in priority.
		- We can pair it with S, ez game.
## Rules ALL
- ![[Pasted image 20230124171917.png|300]]
