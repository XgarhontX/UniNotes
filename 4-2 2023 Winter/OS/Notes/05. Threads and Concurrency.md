# Recap: Processes
- A process includes
	- An Address Space
	- OS resources (e.g., open files), accounting information, priviledges
	- Execution state (PC, SP, regs, etc.)
- Creating a new process is costly
	- Because of all the data structures that must be allocated and initialized
- Communicating between processes is also costly
	- Most communication goes through the OS 
		- Overhead of system calls and copying data
		- So the process does I/O call and pauses
## Web server example (Google Chrome)
- Multiple simultaneous requests/tabs
	- Forks off copies of itself (same program)
- To execute them, we need to
	- Create several processes that execute in parallel
	- Have the OS schedule these processes in parallel
- This situation is **very inefficient**
	- Space: PCB, page tables, etc.
	- Time: create data structures, fork and copy address space, etc.
# Threads
- Motivation: separating shared things from unshared things of a process.
- Modern OSes separate the concepts of processes and threads
	- The thread defines a sequential execution stream within a process (PC, SP, registers)
	- The process defines the address space and general process attributes (everything but threads of execution)
- A thread is bound to a single process
	- Processes, however, can have multiple threads
- Threads become the unit of scheduling
	- Processes are now the containers in which threads execute
	- Processes become static, threads are the dynamic entities
## Threads in a Process
- ![[Pasted image 20230126155920.png|300]]
	- Each thread has their own registers and stack
	- The heap is shared. 
		-  ![[Pasted image 20230126160308.png|350]]
			- (Uh oh stinky. We are going to have conflicts when a thread access and change the same memory.)
## Why Process/Thread Separation
- Easier to support multithreaded applications
	- Concurrency does not require creating new processes 
- Concurrency (multithreading) can be very useful
	- Allowing one process to use multiple CPUs/cores
		- Divide and Conquer, yay!
	- Handling concurrent events (e.g., Web requests)
	- Allowing one program to overlap I/O and computation
- So multithreading is even useful on a uniprocessor
	- Although today even cell phones are multicore 
- But, brings a whole new meaning to Spaghetti Code
	- Forcing OS students to learn about synchronization...
	- Thread safe vs not Thread safe implementation
# Thread Package API
- Create a new thread (pthread_create)
	- ![[Pasted image 20230126162929.png|400]]
		- needs name, attribute (leave NULL rn), the pointer to the method/routine, arguments.
		- returns int of success or not
- Wait for thread to exit (pthread_join)
	- ![[Pasted image 20230126162940.png|400]]
		- needs pointer to thread, the value of what the thread returns (for the main thread to use)
		- returns int of success or not
## Example: Thread Creation
- ![[Pasted image 20230126162824.png|250]]
	- mythread() (the routine) takes in a void*. We just have to typecast it to char* when needed
	- pthread_t p1 & p2 got its address passed to Pthread_create()
	- Threads are non-deterministic
		- A or B can print first here because of its similar short execution time.
		- A potential execution orders
			- ![[Pasted image 20230126170152.png|500]]
			- ![[Pasted image 20230126170335.png|450]]
			- ![[Pasted image 20230126170409.png|450]]
			- But what if we cared about order?
## Too Much Milk
- ![[Pasted image 20230126171201.png|300]]
	- Analogy for read, evaluate, write stages of two threads that manipulates the same global variable overlapping and messing up.
		- This is called Racing. Both is Racing to write LAST, which is the value saved.
## Race Condition
- ![[Pasted image 20230126172351.png|400]]
	- Both Threads mov the integer to the register increment into register, then i++ it.
		- Here, Thread 2 loses, because Thread 1 writes last.
	- What is happening with our counter? 
		- When counter=50, consider code: counter = counter+1
		- If synchronized, counter will = 52
## Summary: Shared Resources
- We need to synchronize the threads to share the resources in turn.
	- RIP multithreading if all data is shared, so we need algorithms like Divide and Conquer
- For any shared data structure in the heap. (stack is thread independent)
	- Buffers, queues, lists, hash tables, etc.
# Mutual Exclusion
- One way to ensure who wins the race is to only let one thread “compete”; this is called mutual exclusion.
- Code that uses mutual exclusion to synchronize its execution is called a critical section.
	- Only one thread at a time can execute in the critical section
	- All other threads are forced to wait on entry
	- When a thread leaves a critical section, another can enter
- ![[Pasted image 20230126173140.png|250]]
	- Only one Thread can use this method at a time.
		- But the return doesn't have to be protected because the balance variable is in the stack. It is locally correct