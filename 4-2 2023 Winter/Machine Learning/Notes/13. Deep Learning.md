# Deep Learning
## Tradition vs Deep Learning
- In Deep Learning, Feature Extraction is also a trained model, instead of being hand-crafted (e.g.) CountVectorizer)
- A technique is considered Deep Learning if it has "more than one stage of non-linear feature transformation".
	- Deep Learning = Learning Hierarchical Representations
	- ![[Pasted image 20230225155005.png|350]]
		- These features are not defined by us, it is learned by the model.
## Image, Text, Speech pipeline
- ![[Pasted image 20230225155238.png|350]]
	- Image Deep Learning started popping off 2012 (ImageNet competition)
	- Text started 2016
		- 2018 BERT model
	- Deep Learning is state of the art now
		- We finally have enough data (Deep Learning is data hungry) and enough CPU power
# Convolutional Neural Networks
- Great at finding patterns, e.g. images.
- Best data for CNN is data that is spatially related.
## Basic Idea
- We have an example CNN that binary predicts if the image (2D array of pixels) is "X" or "O"
	- ![[Pasted image 20230225160027.png|150]]
- All is well until it encounters different transformations
	- ![[Pasted image 20230225160017.png|200]]
	- All it sees is the pixel values itself
		- ![[Pasted image 20230225160147.png|200]]
	- Some pixels will match, some don't
		- ![[Pasted image 20230225160226.png|100]]
			- Maybe there is a pixel similarity threshold, and this is not similar enough so it will classifier not "X"
- The trick CNN uses is to match pieces of the image
	- ![[Pasted image 20230225160354.png|200]]
	- These pieces are are small subset of the image. 3 unique pieces are able to recreate the original "X"
## Filtering
- The algorithm to find similarities between a feature and the image
	- ![[Pasted image 20230225160636.png|250]]
- Aka the Kernel
- Filter values are learned by training the model. You have some starting values, which each gets altered from backpropagation & gradient descent.
	- They are often called the CNN's weights. 
	- Historically, filters were hand made by the programmer.
### Step by Step
- We have a feature. It's 3x3.
- ![[Pasted image 20230225160721.png|200]]
	- Since the small piece matches completely, we get a output of all 1's
		- ![[Pasted image 20230225160821.png|70]]
- Then by taking the avg of the result. that is how similar the piece was.
	- ![[Pasted image 20230225160904.png|300]]
		- Note that similarity down, like a DP algorithm.
- Keep going
	- ![[Pasted image 20230225161039.png|300]]
		- This is a stride of 1 (shifting 1 position). The bigger the stride, the smaller the map.
- This makes a map of how close the feature appears in the original
	- Feature
		- ![[Pasted image 20230225161152.png|50]]
	- Map
		- ![[Pasted image 20230225161135.png|400]]
			- The diagonal of 1.00 means the feature exist there
	- This is why it's "Convolution", since it's trying every possible match.
- Repeat for all features
	- ![[Pasted image 20230225161347.png|300]]
		- "circle x" thing denotes Convolution operation
## Pooling
- We want to shrinking the image stack from the Convolution.
	- ![[Pasted image 20230225161434.png|250]]
### Step by Step
- Let's do Max Pooling w/ a 2x2 window and stride of 2, so now we have another map for all possible window locations
- The first window location
	- ![[Pasted image 20230225161720.png|300]]
- Second
	- ![[Pasted image 20230225161741.png|300]]
- Third
	- ![[Pasted image 20230225161818.png|300]]
- Fourth
	- ![[Pasted image 20230225161834.png|300]]
- This is the completed map
	- ![[Pasted image 20230225162116.png|300]]
		- We still get that diagonal of similarities, but it is now much smaller.
		- Extra: The more we decrease in shape, the more weighted the values become. We can lower their weight by padding around the data. Zero padding is placing 0's around the actual data.
			- ![[Pasted image 20230225165259.png|200]]
- Do it for all features
	- ![[Pasted image 20230225162225.png|300]]
## Normalization
- To have nicer math later on, we want to use a Rectified Linear Unit (changes all negative to 0)
	- ![[Pasted image 20230225162353.png|300]]
## Layers
- Stack the LAYERS
	- ![[Pasted image 20230225162427.png|300]]
		- You can change the ordering, it depends on the situation for most optimal.
- STACK THE LAYERS
	- ![[Pasted image 20230225162525.png|500]]
		- More filtering, the smaller the output
## Fully Connected Layer
- This is at the end, go to the polls and vote moment.
- Fully Connected Layer means every layer's output values gets a vote
	- This is the values from "X" features
		- ![[Pasted image 20230225162701.png|100]]![[Pasted image 20230225163019.png|230]]
			- Higher means more similar and probable
	- This is the value from "O" features
		- ![[Pasted image 20230225163117.png|230]]
			- (The green lines & numbers are different btw)
	- Do a vote for each classification, which is the average for the features
		- ![[Pasted image 20230225163215.png|100]]
- You can stack the stack
	- ![[Pasted image 20230225163307.png|300]]
## The Stack
- A possible CNN
	- ![[Pasted image 20230225163339.png|500]]
## Training
1. Do the CNN calculation
2. Backpropagation by comparing to the correct answer and punish 
	- ![[Pasted image 20230225163600.png|220]]
3. Gradient Descent
	- ![[Pasted image 20230225163649.png|150]]
## Hyperparameters
- ![[Pasted image 20230225163717.png|150]]
## Other Data
- Any data that is 2D or higher can be used
### Images
- ![[Pasted image 20230225163856.png|100]] Pixels are spatially related, one axis for each, creating matrix.
### Sound
- ![[Pasted image 20230225163936.png|100]] Spectrograms, frequency to time are spatially related, creating matrix.
### Text
- ![[Pasted image 20230225164053.png|100]] Word to position in sentence, spatially related creating matrix.
	- CNN is ok with text, but Recurrent Neural Networks (RNNs) such as Long Short-Term Memory networks (LSTMs) are the more often used.
## Limitations
- CNN are only good at local spatial patterns
	- If it doesn't look like an image type beat, it probably sucks at it.
- e.g. Customer details matrix
	- ![[Pasted image 20230225164309.png|200]]
		- You can scramble the either the rows or columns, and the data is still the same.
# Is Deep Learning the Future?
- Deep Learning doesn't replace other models we learned about.
## Strengths and Weaknesses
- CNN is good with grid-like topology, spatial data.
- Ensembles (i.e. of Decision Trees) are state of the art for tabular data.
- Deep Learning is data hungry and CPU hungry
- When limited labeled training data is available, you can pre-train a deep network on a related dataset/task
	- Transfer learning (find pre-trained neural network as crutch)
	- Word embedding (e.g. BERT)
- Deep Learning is quite a black box when training. 
	- Gradient Descent is sensitive, the building blocks are all crazy math, can't explain why it chose a prediction nicely.
		- Unlike DT branches, what are you gonna say about CNN? "Ya dude, it found the backpropagation minimum that predicts your mom is fat."
	- Stable Diffusion company is getting sued for copyright infringement via dataset used
## Adversarial Examples
- You can train a Deep Learning model to fool another Deep Learning model
- e.g. Another trained model predicts that putting these exact stickers on a stop signs makes it classify it incorrectly
	- ![[Pasted image 20230225170703.png|100]]
- e.g. Putting a specific noise pattern on an image can trick a neural network classify it