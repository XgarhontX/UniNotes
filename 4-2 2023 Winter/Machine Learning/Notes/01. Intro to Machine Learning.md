# What's Machine Learning?
- The field of programs that automatically improve with experience.
- Automating automation (programs)
- Supervised Machine Learning: We give input data and expected/desired output to the computer, and the computer gives a program.
	- ![[Pasted image 20230102161929.png|200]]
# Linear Regression
- Aka best fit line be like
- We want to
	- ![[Pasted image 20230102163149.png|180]]
		- Squared Error
			- ![[Pasted image 20230102163218.png|120]] 
	- We can use the derivative to find the minimum
		- ![[Pasted image 20230102164113.png|300]] (Differential Equations, solve the system)
		- ![[Pasted image 20230102164202.png|200]]
## Regression VS Classify
- Regression predicts a number
- Classify predicts a binary classification (pos/neg instances)
## Example: Predicting student success
![[Pasted image 20230102162825.png|75]]![[Pasted image 20230102162837.png|200]] ---> ![[Pasted image 20230102162956.png|200]]![[Pasted image 20230102164454.png|200]]
- The linear regression here is a model/program interpolated from the given in/output data
# Classification and K-Fold Cross-Validation
## Example from biomedical domain
- ![[Pasted image 20230102164715.png|300]]![[Pasted image 20230102164738.png|200]]
- ![[Pasted image 20230102164929.png|300]]
	- For simplicity, we'll only consider 2 features for this ex.
	- The sectioned off green corner is what we considering as the negative cases
		- We can have a complex boundary
			- ![[Pasted image 20230102165144.png|200]]
				- But here, we are overfitting, doing well only on seen data and sucking at new unseen data. The yellow new patient is in the benign section, but its surrounding is dominated by malignant cases.
				- There are places later in the course we can use complex boundaries
		- We can have a simple boundary
			- ![[Pasted image 20230102165534.png|200]]
		- Well, which one is the best boundary?
## Model Evaluation
- By Accuracy (How many new instances were classified correctly?)
	- ![[Pasted image 20230102171552.png|200]]
	- However, if we do this on the complex boundary above, it has an accuracy of 100%, which we know is overfitting
- Instead of training the model directly on all available training data, split the data in a training set (e.g. 90% of the data) and a test set (the other 10%).
	- But depending on the which data point is selected, we can come up with varying models
### K-Fold Cross Validation
- In order to consider every data points in both train and test sets and finding the best measure of predictive capability of a model, we can do this:
	- Partition data into k disjoint subsets  
	- for i = 1 to k  
		- hold out subset i for testing and train on the remaining subsets  
	- Report average performance
- 10-Fold
	- ![[Pasted image 20230102170437.png|400]]
# Applications
- Web search, Computational biology, Finance, E-commerce, Space exploration, Robotics, Information extraction, Social networks, Debugging, etc.
- In a nutshell:
	- Tens of thousands of machine learning algorithms  
	- Hundreds new every year  
	- Every machine learning algorithm has three components:  
		- Representation  
		- Evaluation  
		- Optimization
